# The yaml format follows W&B's: (https://docs.wandb.ai/guides/track/config)

# GPU
device_ids:
  - 0

# data pipeline
ucr_dataset_name: "WordSynonyms"
train_data_ratio: 0.8
test_data_ratio: 0.2
train_random_seed: 0
test_random_seed: 0
data_scaling: True
batch_size: 256
num_workers: 0

# augmentations
subseq_len: 135
used_augmentations: ["RC", "AmpR", "Vshift"]
AmpR_rate: 0.3
Vshift_rate: 0.5

# backbone-encoder
in_channels_enc: 1
n_blocks_enc:
  - 1
  - 1
  - 1
  - 1
out_channels_enc: 64
kernel_size_enc: 3
norm_layer_type_enc: "BatchNorm"
dropout_rate_enc: 0.

# framework
proj_hid_vibcreg: 4096
proj_out_vibcreg: 4096
norm_layer_type_proj_vibcreg: "BatchNorm"
add_IterN_at_the_last_in_proj_vibcreg: True
weight_on_msfLoss: 0.
use_predictor_msf: False

# framework loss
lambda_vibcreg: 25.
mu_vibcreg: 25.
nu_vibcreg: 25.
loss_type_vibcreg: "mse"

# framework utility (belongs to the abstract class: `Utility_SSL`)
n_epochs: 100
framework_type: "vibcreg"
use_wandb: True
project_name: "RLonUCR"
n_neighbors_kNN: 5
n_jobs_for_kNN: 10
model_saving_epochs:
  - 10
  - 100

# optimizer
lr: 0.001
weight_decay: 0.00001

# misc
tsne_analysis_log_epochs: [1, 10, 20, 30, 40, 50, 100]
